#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import argparse
import subprocess
from pathlib import Path
from config import WORKFLOW, CONDOR, get

class AbacusFlowManager:
    def __init__(self, work_dir):
        self.work_dir = Path(work_dir).absolute()
        self.flow_stages = list(WORKFLOW.keys())
        
    def generate_scripts(self, stru_path=None, suffix='*.vasp'):
        """生成提交脚本"""
        # 读取结构文件列表
        if stru_path:
            search_path = Path(stru_path)
        else:
            # 回退到配置文件或默认值
            conf_path = get('STRU', 'PATH', '')
            if conf_path:
                search_path = Path(conf_path)
            else:
                search_path = Path('InputPoscar')
                if not search_path.exists():
                    search_path = Path('.')
        
        # 确定后缀
        stru_suffix = get('STRU', 'SUFFIX', suffix)
                
        # 处理单个文件还是目录
        if search_path.is_file():
            structure_files = [search_path]
        else:
            structure_files = list(search_path.glob(stru_suffix))
        
        if not structure_files:
            print(f"No structure files found in {search_path} with suffix {stru_suffix}")
            return
            
        print(f"Found {len(structure_files)} structure files.")
        
        # 为每个结构文件生成提交脚本
        generated_scripts = []
        for stru_file in structure_files:
            script = self._create_job_script(stru_file)
            generated_scripts.append(script)
        
        return generated_scripts
            
    def _create_job_script(self, stru_file):
        """为单个结构创建完整的流程控制脚本"""
        job_name = stru_file.stem
        # 计算子目录 work_cal/job_name
        job_dir = self.work_dir / job_name
        
        # 确保计算目录存在
        if not job_dir.exists():
            job_dir.mkdir(parents=True)
            
        # 脚本生成在计算目录内：work_cal/job_name/job_name.sh
        script_name = job_dir / f"{job_name}.sh"
        
        # 主入口文件（在 abacus 的父目录，即项目根目录）
        abacus_py = Path(__file__).parent.parent / 'abacus.py'
        abacus_sh = Path(__file__).parent.parent / 'abacus.sh'
        monitor_py = Path(__file__).parent / 'monitor.py'  # 监控脚本
        stru_file_abs = stru_file.absolute()
        
        # 准备脚本内容
        # 脚本已在计算目录内（work_cal/job_name/），直接在当前目录操作
        
        # 获取 conda 和 python 路径配置
        conda_path = get('ENV', 'CONDA_PATH', '/XYFS01/nscc-gz_pinchen_1/sf_install/miniconda3')
        conda_env = get('ENV', 'CONDA_ENV', 'dftflow')
        
        # 获取 ABACUS 可执行文件路径
        abacus_dir = get('ABACUS', 'ABACUS_DIR', '/XYFS01/nscc-gz_pinchen_1/sf_box/abacus-develop-LTSv3.10.0/bin')
        abacus_exe = get('ABACUS', 'ABACUS_EXE', 'abacus')
        abacus_bin = f"{abacus_dir}/{abacus_exe}"
        
        # 获取 module 信息
        modules_str = get('MODULE', 'MODULES', 'intel/oneapi2023.2_noimpi mpi/mpich/4.1.2-icc-oneapi2023.2-ch4')
        
        script_content = [
            "#!/bin/bash",
            f"# Job script for {job_name}",
            f"# Generated by abacusflow",
            f"# Run this script from: {job_dir}",
            "",
            "# ===== 环境初始化 =====",
            "# 设置 OpenMP 线程数（避免超线程问题）",
            "export OMP_NUM_THREADS=1",
            "",
            "# 激活 conda 环境",
            f"source {conda_path}/etc/profile.d/conda.sh",
            f"conda activate {conda_env}",
            "",
            "# 加载必要的 module",
            f"# MODULES: {modules_str}",
            "export MODULESHOME=/usr/share/modules",
            "export MODULEPATH=/APP/u22/x86/modulepath/Compilers:/APP/u22/x86/modulepath/application",
            "export MODULES_CMD=/usr/lib/x86_64-linux-gnu/modulecmd.tcl",
            "ml() { module ml \"$@\"; }",
            "module() { _module_raw \"$@\" 2>&1; }",
            "_module_raw() { eval `/usr/bin/tclsh8.6 /usr/lib/x86_64-linux-gnu/modulecmd.tcl bash \"$@\"`; }",
            "",
            f"# 加载模块",
            f"for mod in {modules_str}; do",
            "  module load $mod",
            "done",
            "",
            "# 确保在正确的目录",
            f"cd {job_dir} || exit 1",
            "",
            "echo '[...]TASK START!'",
            f"echo '[...]Structure: {stru_file}'",
            f'echo "[...]Working directory: $(pwd)"',
            "",
            f"# 复制结构文件到当前目录",
            f"if [ ! -f STRU.vasp ]; then",
            f"  cp {stru_file_abs} ./STRU.vasp",
            "fi",
            "",
            "# 初始化状态日志和时间统计",
            "stat_log=stat.log",
            "> $stat_log",
            "time_log=time.log",
            "> $time_log",
            "echo '# Stage statistics' > $time_log",
            "echo '# Format: Stage | Duration(s) | Nodes | Cores | Core-hours | Status' >> $time_log",
            "WORKFLOW_START=$(date +%s)",
            ""
        ]
        
        # 遍历工作流阶段
        for stage in self.flow_stages:
            stage_config = WORKFLOW[stage]
            template = stage_config.get('template', stage)
            nodes = stage_config.get('node', 1)
            cores = stage_config.get('core', 64)
            try_num = stage_config.get('try_num', 2)
            ignore_error = stage_config.get('ignore_error', "False")
            partition = get('ALLOW', 'PARTITION', 'deimos')
            
            script_content.extend([
                f"echo '[...]start {stage} task'",
                f"{stage.upper()}_START=$(date +%s)",
                f"echo \"[INFO] {stage} started at $(date '+%Y-%m-%d %H:%M:%S')\"",
                f"if [ ! -d {stage} ];then",
                f"  mkdir {stage} && cd {stage} || exit",
                "else",
                f"  cd {stage}",
                "fi",
                "",
                f"echo '[...]prepare {stage} inputs.'",
                # 调用 abacusHT.py 生成输入文件
                # 注意：此时我们在 work_cal/job_name/Stage 目录下
                # STRU.vasp 在上一级目录 (work_cal/job_name)
                f"python {abacus_py} generate --work_dir . --stage {template}",
            ])
            
            # 如果配置了 ignore_error，创建 ignore.txt 标记文件
            if ignore_error == "True":
                script_content.extend([
                    "",
                    f"# Create ignore.txt marker for {stage} (ignore_error=True in workflow.json)",
                    "touch ignore.txt",
                ])
            
            script_content.extend([
                "",
                f"for try_num in $(seq 0 {try_num-1})",
                "  do",
                f"  echo \"[...]task {stage} round: $try_num on {nodes} node {cores} core\"",
                f"  ",
                f"  # 运行 ABACUS 并实时监控（yhrun 标准输出）",
                f"  # 使用 stdbuf 强制行缓冲，tee 同时保存和输出，python -u 无缓冲监控",
                f"  if command -v stdbuf >/dev/null 2>&1 && [ -f {monitor_py} ]; then",
                f"    stdbuf -oL -eL yhrun -N {nodes} -n {cores} -p {partition} {abacus_bin} 2>&1 | tee running.log | python -u {monitor_py}",
                f"  else",
                f"    # 降级方案：没有 stdbuf 或 monitor.py 时直接运行",
                f"    yhrun -N {nodes} -n {cores} -p {partition} {abacus_bin} > running.log 2>&1",
                f"  fi",
                "  ",
                "  # 检查计算结果（不管 yhrun 返回值，都检查错误和收敛性）",
                f"  echo \"[...]checking iteration $try_num result...\"",
                f"  python {abacus_py} errors --work_dir .",
                f"  python {abacus_py} converge --work_dir .",
                "  ",
                "  # 如果收敛成功，退出循环",
                "  if [ -f \"converge.txt\" ]; then",
                f"    echo \"[...]iteration $try_num: converged successfully!\"",
            ])
            
            # 只在 Test_spin 阶段检测磁矩
            if 'spin' in stage.lower() or 'spin' in template.lower():
                script_content.append(f"    python {abacus_py} spin --work_dir .")
            
            script_content.extend([
                "    break",
                "  fi",
                "  ",
                "  # 未收敛且不是最后一次，准备下一次迭代",
                f"  if [ $try_num -lt {try_num-1} ]; then",
                "    echo '[...]calculation not done, prepare to next loop'",
                f"    python {abacus_py} update --work_dir . --try_num $try_num --stage {stage}",
                "  else",
                "    echo '[...]last iteration completed'",
                "  fi",
                "done",
                "",
                "if [ ! -f 'converge.txt' ]; then",
                "  echo '[...]Job failed or not converged'",
                "  # 优先检查是否有真正的错误（error.txt），如果有则必须退出",
                "  if [ -f 'error.txt' ]; then",
                "    echo '[...]Error detected (error.txt exists), cannot continue even with ignore.txt'",
                f"    echo '{stage} failed' >> ../stat.log",
                "    exit 1",
                "  elif [ ! -f 'ignore.txt' ]; then",
                "    echo '[...]Not converged and no ignore marker, exiting...'",
                f"    echo '{stage} failed' >> ../stat.log",
                "    exit 1",
                "  else",
                "    echo '[...]Not converged but can be ignored (ignore.txt exists), continuing...'",
            ])
            
            # 只在 Test_spin 阶段检测磁矩
            if 'spin' in stage.lower() or 'spin' in template.lower():
                script_content.append(f"    python {abacus_py} spin --work_dir .")
            
            script_content.extend([
                f"    echo '{stage} success (ignored)' >> ../stat.log",
                "  fi",
                "else",
                f"  echo '[...]{stage} job done!'",
            ])
            
            # 只在 Test_spin 阶段检测磁矩
            if 'spin' in stage.lower() or 'spin' in template.lower():
                script_content.append(f"  python {abacus_py} spin --work_dir .")
            
            script_content.extend([
                f"  echo '{stage} success' >> ../stat.log",
                "fi",
                "",
                f"# 计算 {stage} 阶段用时和资源消耗",
                f"{stage.upper()}_END=$(date +%s)",
                f"{stage.upper()}_DURATION=$(( ${stage.upper()}_END - ${stage.upper()}_START ))",
                f"{stage.upper()}_HOURS=$(awk \"BEGIN {{printf \\\"%.4f\\\", ${stage.upper()}_DURATION/3600}}\")",
                f"{stage.upper()}_CORE_HOURS=$(awk \"BEGIN {{printf \\\"%.2f\\\", {nodes}*{cores}*${stage.upper()}_HOURS}}\")",
                f"echo \"[INFO] {stage} completed in ${{{stage.upper()}_DURATION}}s (${{{stage.upper()}_HOURS}}h)\"",
                f"echo \"[INFO] {stage} consumed ${{{stage.upper()}_CORE_HOURS}} Core-hours ({nodes}nodes * {cores}cores * ${{{stage.upper()}_HOURS}}h)\"",
                f"echo \"{stage}|${{{stage.upper()}_DURATION}}|{nodes}|{cores}|${{{stage.upper()}_CORE_HOURS}}|$(tail -1 ../stat.log 2>/dev/null || echo 'unknown')\" >> ../time.log",
                "",
                "cd ..",
                ""
            ])
            
        # 添加脚本结束部分
        script_content.extend([
            "",
            "# ===== 计算总用时和资源消耗 =====",
            "WORKFLOW_END=$(date +%s)",
            "TOTAL_DURATION=$((WORKFLOW_END - WORKFLOW_START))",
            "TOTAL_HOURS=$(awk \"BEGIN {printf \\\"%.4f\\\", $TOTAL_DURATION/3600}\")",
            "",
            "echo ''",
            "echo '======================================================================'",
            "echo '                    WORKFLOW SUMMARY'",
            "echo '======================================================================'",
            "echo ''",
            "echo '[INFO] Individual Stage Statistics:'",
            "echo '----------------------------------------------------------------------'",
            "printf '%-15s %-12s %-8s %-8s %-15s %-15s\\n' 'Stage' 'Duration(s)' 'Nodes' 'Cores' 'Core-hours' 'Status'",
            "echo '----------------------------------------------------------------------'",
            "tail -n +3 time.log | while IFS='|' read -r stage duration nodes cores core_hours status; do",
            "  hours=$(awk \"BEGIN {printf \\\"%.2f\\\", $duration/3600}\")",
            "  printf '%-15s %-12s %-8s %-8s %-15s %-15s\\n' \"$stage\" \"${duration}s (${hours}h)\" \"$nodes\" \"$cores\" \"$core_hours\" \"$status\"",
            "done",
            "echo '----------------------------------------------------------------------'",
            "",
            "# 计算总 Core-hours",
            "TOTAL_CORE_HOURS=$(tail -n +3 time.log | awk -F'|' '{sum+=$5} END {printf \"%.2f\", sum}')",
            "",
            "echo ''",
            "echo '[INFO] Total Workflow Statistics:'",
            "echo \"  Total Duration    : ${TOTAL_DURATION}s (${TOTAL_HOURS}h)\"",
            "echo \"  Total Core-hours  : ${TOTAL_CORE_HOURS}\"",
            "echo \"  Workflow Start    : $(date -d @$WORKFLOW_START '+%Y-%m-%d %H:%M:%S')\"",
            "echo \"  Workflow End      : $(date -d @$WORKFLOW_END '+%Y-%m-%d %H:%M:%S')\"",
            "echo ''",
            "echo '======================================================================'",
            "",
            "# ===== 汇总结果 =====",
            f"python {abacus_py} summary --root {job_dir}",
            "",
            "echo '[...]ALL STAGES COMPLETED!'",
            "echo 'Workflow completed' >> $stat_log",
            ""
        ])
        
        # 写入脚本文件
        with open(script_name, 'w') as f:
            f.write('\n'.join(script_content))
        print(f"Generated script: {script_name}")
        os.chmod(script_name, 0o755)
        return str(script_name)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='ABACUS Flow Manager')
    parser.add_argument('action', choices=['init', 'submit', 'status'], help='Action to perform')
    args = parser.parse_args()
    
    # 默认工作目录为 work_cal
    manager = AbacusFlowManager('work_cal')
    
    if args.action == 'init':
        manager.generate_scripts()
