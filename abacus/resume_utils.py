#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»­ç®—åŠŸèƒ½è¾…åŠ©å‡½æ•°æ¨¡å—

æä¾›å·¥ä½œæµç»­ç®—æ‰€éœ€çš„å„ç§æ£€æµ‹å’Œå¤„ç†åŠŸèƒ½ï¼š
- çŠ¶æ€æ£€æµ‹
- stat.log è§£æ
- ç»­ç®—èµ·ç‚¹ç¡®å®š
- æ—¥å¿—å¤‡ä»½
- é”™è¯¯æ¸…ç†
"""

import re
import shutil
import subprocess
from pathlib import Path


def detect_stage_status(stage_dir, stage_name):
    """
    æ£€æµ‹é˜¶æ®µçŠ¶æ€
    
    Args:
        stage_dir: é˜¶æ®µç›®å½•è·¯å¾„ (Pathå¯¹è±¡)
        stage_name: é˜¶æ®µåç§°
    
    Returns:
        çŠ¶æ€å­—ç¬¦ä¸²: 'success', 'ignored', 'failed', 'incomplete', 'not_started'
    """
    if not stage_dir.exists():
        return 'not_started'
    
    # ä¼˜å…ˆçº§1: error.txt å­˜åœ¨ â†’ å¤±è´¥
    if (stage_dir / 'error.txt').exists():
        return 'failed'
    
    # ä¼˜å…ˆçº§2: converge.txt å­˜åœ¨ â†’ æˆåŠŸ
    if (stage_dir / 'converge.txt').exists():
        return 'success'
    
    # ä¼˜å…ˆçº§3: ignore.txt å­˜åœ¨ä½†æ—  converge.txt â†’ è¢«å¿½ç•¥
    if (stage_dir / 'ignore.txt').exists():
        return 'ignored'
    
    # ä¼˜å…ˆçº§4: æœ‰è¿è¡Œç—•è¿¹ä½†æ— ç»“è®º â†’ æœªå®Œæˆ
    if (stage_dir / 'running.log').exists():
        return 'incomplete'
    
    return 'not_started'


def parse_stat_log(work_dir):
    """
    è§£æ stat.logï¼Œè¿”å›é˜¶æ®µçŠ¶æ€æ˜ å°„
    
    Args:
        work_dir: å·¥ä½œç›®å½•è·¯å¾„ (Pathå¯¹è±¡)
    
    Returns:
        å­—å…¸: {stage_name: status}
        ä¾‹å¦‚: {'Test_spin': 'success', 'Relax': 'failed'}
    """
    stat_log = work_dir / 'stat.log'
    if not stat_log.exists():
        return {}
    
    status_map = {}
    try:
        for line in stat_log.read_text().strip().split('\n'):
            if not line or line.startswith('#'):
                continue
            
            # è§£ææ ¼å¼: "Test_spin success" æˆ– "Coarse_relax success (ignored)"
            parts = line.split()
            if len(parts) >= 2:
                stage = parts[0]
                if 'success' in line:
                    status_map[stage] = 'ignored' if 'ignored' in line else 'success'
                elif 'failed' in line:
                    status_map[stage] = 'failed'
    except Exception as e:
        print(f"[WARNING] Failed to parse stat.log: {e}")
    
    return status_map


def determine_resume_point(work_dir, workflow_stages):
    """
    ç¡®å®šç»­ç®—èµ·ç‚¹
    
    Args:
        work_dir: å·¥ä½œç›®å½•è·¯å¾„ (Pathå¯¹è±¡)
        workflow_stages: å·¥ä½œæµé˜¶æ®µåˆ—è¡¨
    
    Returns:
        (resume_stage_index, reason) å…ƒç»„
        å¦‚æœæ‰€æœ‰é˜¶æ®µéƒ½å®Œæˆï¼Œè¿”å› (None, reason)
    """
    stat_status = parse_stat_log(work_dir)
    
    for i, stage in enumerate(workflow_stages):
        stage_dir = work_dir / stage
        stage_status = detect_stage_status(stage_dir, stage)
        stat_log_status = stat_status.get(stage, 'not_started')
        
        # æƒ…å†µ1: stat.log è®°å½•å¤±è´¥ â†’ ä»è¿™é‡Œå¼€å§‹
        if stat_log_status == 'failed':
            return i, f"{stage} failed in previous run"
        
        # æƒ…å†µ2: é˜¶æ®µæœªå¼€å§‹ â†’ ä»è¿™é‡Œå¼€å§‹
        if stage_status == 'not_started':
            return i, f"{stage} not started yet"
        
        # æƒ…å†µ3: é˜¶æ®µæœªå®Œæˆ â†’ ä»è¿™é‡Œå¼€å§‹
        if stage_status == 'incomplete':
            return i, f"{stage} incomplete"
        
        # æƒ…å†µ4: å¤±è´¥ä½† stat.log æœªè®°å½• â†’ ä»è¿™é‡Œå¼€å§‹
        if stage_status == 'failed':
            return i, f"{stage} has error.txt"
        
        # æƒ…å†µ5: æˆåŠŸæˆ–è¢«å¿½ç•¥ â†’ ç»§ç»­æ£€æŸ¥ä¸‹ä¸€ä¸ª
        if stage_status in ['success', 'ignored']:
            continue
    
    # æ‰€æœ‰é˜¶æ®µéƒ½å®Œæˆäº†
    return None, "All stages completed"


def backup_logs(work_dir):
    """
    å¤‡ä»½ stat.log å’Œ time.log
    è‡ªåŠ¨é€’å¢ç¼–å·: stat0.log, stat1.log, ...
    
    Args:
        work_dir: å·¥ä½œç›®å½•è·¯å¾„ (Pathå¯¹è±¡)
    
    Returns:
        (stat_backup, time_backup) å…ƒç»„ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™ä¸º None
    """
    backups = []
    
    for log_name in ['stat.log', 'time.log']:
        log_file = work_dir / log_name
        
        if not log_file.exists():
            backups.append(None)
            continue
        
        # æŸ¥æ‰¾å¯ç”¨çš„å¤‡ä»½ç¼–å·
        backup_num = 0
        base_name = log_name.replace('.log', '')
        
        while True:
            backup_name = work_dir / f'{base_name}{backup_num}.log'
            if not backup_name.exists():
                break
            backup_num += 1
        
        # æ‰§è¡Œå¤‡ä»½
        try:
            shutil.copy2(log_file, backup_name)
            print(f"[BACKUP] {log_name} -> {backup_name.name}")
            backups.append(backup_name.name)
        except Exception as e:
            print(f"[WARNING] Failed to backup {log_name}: {e}")
            backups.append(None)
    
    return tuple(backups)


def clean_stage_errors(work_dir, start_stage):
    """
    æ¸…ç†ç»­ç®—èµ·ç‚¹é˜¶æ®µçš„ error.txt
    
    Args:
        work_dir: å·¥ä½œç›®å½•è·¯å¾„ (Pathå¯¹è±¡)
        start_stage: ç»­ç®—èµ·ç‚¹é˜¶æ®µåç§°
    """
    stage_dir = work_dir / start_stage
    error_file = stage_dir / 'error.txt'
    
    if error_file.exists():
        try:
            error_file.unlink()
            print(f"[CLEAN] Removed {start_stage}/error.txt")
        except Exception as e:
            print(f"[WARNING] Failed to remove {start_stage}/error.txt: {e}")
        
        # åŒæ—¶æ¸…ç† stat.log ä¸­è¯¥é˜¶æ®µçš„å¤±è´¥è®°å½•
        stat_log = work_dir / 'stat.log'
        if stat_log.exists():
            try:
                lines = stat_log.read_text().strip().split('\n')
                # ç§»é™¤è¯¥é˜¶æ®µçš„ failed è®°å½•
                new_lines = [line for line in lines 
                           if not (line.startswith(f'{start_stage} ') and 'failed' in line)]
                stat_log.write_text('\n'.join(new_lines) + '\n')
                print(f"[CLEAN] Removed '{start_stage} failed' from stat.log")
            except Exception as e:
                print(f"[WARNING] Failed to clean stat.log: {e}")


def detect_resume_number(stage_dir):
    """
    æ£€æµ‹å½“å‰æ˜¯ç¬¬å‡ æ¬¡ç»­ç®—
    
    Args:
        stage_dir: é˜¶æ®µç›®å½•è·¯å¾„ (Pathå¯¹è±¡)
    
    Returns:
        resume_num: 0è¡¨ç¤ºé¦–æ¬¡ç»­ç®—ï¼Œ1è¡¨ç¤ºç¬¬2æ¬¡ç»­ç®—ï¼Œä»¥æ­¤ç±»æ¨
    """
    if not stage_dir.exists():
        return 0
    
    # æŸ¥æ‰¾ç°æœ‰çš„ *_R* æ–‡ä»¶
    max_resume = -1
    
    for f in stage_dir.glob('*_R*_*'):
        if f.is_file():
            # æ–‡ä»¶åæ ¼å¼: INPUT_R0_0, KPT_R1_2 ç­‰
            match = re.match(r'.*_R(\d+)_', f.stem)
            if match:
                resume_num = int(match.group(1))
                max_resume = max(max_resume, resume_num)
    
    return max_resume + 1


def detect_previous_try_count(stage_dir):
    """
    æ£€æµ‹ä¹‹å‰å¤±è´¥æ—¶å°è¯•äº†å¤šå°‘æ¬¡
    
    Args:
        stage_dir: é˜¶æ®µç›®å½•è·¯å¾„ (Pathå¯¹è±¡)
    
    Returns:
        try_count: 0è¡¨ç¤ºé¦–æ¬¡å°è¯•å°±å¤±è´¥ï¼Œ1è¡¨ç¤ºå°è¯•äº†2æ¬¡ï¼Œä»¥æ­¤ç±»æ¨
    """
    if not stage_dir.exists():
        return 0
    
    # æŸ¥æ‰¾å¤‡ä»½æ–‡ä»¶: INPUT0, INPUT1, INPUT2...
    count = 0
    while (stage_dir / f'INPUT{count}').exists():
        count += 1
    
    return count


def should_clean_and_restart(stage_dir, stage_name):
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥æ¸…ç©ºé‡ç®—
    
    Args:
        stage_dir: é˜¶æ®µç›®å½•è·¯å¾„ (Pathå¯¹è±¡)
        stage_name: é˜¶æ®µåç§°
    
    Returns:
        (should_clean, reason) å…ƒç»„
    """
    if not stage_dir.exists():
        return False, "Directory does not exist"
    
    try_count = detect_previous_try_count(stage_dir)
    
    # æƒ…å†µAï¼šé¦–æ¬¡å°è¯•å°±å¤±è´¥ â†’ æ¸…ç©ºé‡ç®—
    if try_count == 0:
        return True, "First attempt failed, likely input parameter error"
    
    # æƒ…å†µBï¼šå¤šæ¬¡å°è¯•æœªæ”¶æ•› â†’ æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ä¸­é—´ç»“æœ
    # å¯¹äº Relax ç±»å‹çš„è®¡ç®—ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ STRU_ION_D
    if 'relax' in stage_name.lower():
        out_dirs = list(stage_dir.glob('OUT.*'))
        has_stru_ion = False
        for out_dir in out_dirs:
            if (out_dir / 'STRU_ION_D').exists():
                has_stru_ion = True
                break
        
        if not has_stru_ion:
            return True, f"Multiple attempts ({try_count}) but no STRU_ION_D found"
    
    return False, f"Continue from attempt {try_count}"


def verify_stage_completion(stage_dir, stage_name):
    """
    éªŒè¯é˜¶æ®µæ˜¯å¦çœŸæ­£å®Œæˆï¼ˆæ›´ä¸¥æ ¼çš„æ£€æŸ¥ï¼‰
    
    Args:
        stage_dir: é˜¶æ®µç›®å½•è·¯å¾„ (Pathå¯¹è±¡)
        stage_name: é˜¶æ®µåç§°
    
    Returns:
        (is_complete, checks_dict) å…ƒç»„
    """
    checks = {
        "converge_marker": (stage_dir / "converge.txt").exists(),
        "no_error": not (stage_dir / "error.txt").exists(),
        "has_output_dir": len(list(stage_dir.glob("OUT.*"))) > 0,
        "has_log": len(list(stage_dir.glob("OUT.*/running*.log"))) > 0 or 
                   (stage_dir / "running.log").exists()
    }
    
    # é˜¶æ®µç‰¹å®šæ£€æŸ¥
    if "relax" in stage_name.lower():
        checks["has_stru_ion"] = any((d / "STRU_ION_D").exists() 
                                     for d in stage_dir.glob("OUT.*"))
    elif stage_name == "Scf":
        checks["has_charge"] = any((d / "SPIN1_CHG.cube").exists() 
                                   for d in stage_dir.glob("OUT.*"))
    
    is_complete = all(checks.values())
    return is_complete, checks


def format_status_icon(status):
    """
    æ ¹æ®çŠ¶æ€è¿”å›åˆé€‚çš„å›¾æ ‡
    
    Args:
        status: çŠ¶æ€å­—ç¬¦ä¸²
    
    Returns:
        å›¾æ ‡å­—ç¬¦ä¸²
    """
    icons = {
        'success': 'âœ…',
        'ignored': 'âš ï¸ ',
        'failed': 'âŒ',
        'incomplete': 'ğŸ”„',
        'not_started': 'â­•'
    }
    return icons.get(status, 'â“')


def get_running_jobs_from_slurm(batch_dir):
    """
    ä» Slurm é˜Ÿåˆ—ä¸­è·å–æ­£åœ¨è¿è¡Œçš„ä½œä¸šåˆ—è¡¨
    
    Args:
        batch_dir: æ‰¹å¤„ç†ç›®å½•è·¯å¾„ (Pathå¯¹è±¡)
    
    Returns:
        set: æ­£åœ¨è¿è¡Œçš„ä½œä¸šåç§°é›†åˆï¼ˆä» WorkDir ä¸­æå–ï¼‰
    """
    running_jobs = set()
    
    try:
        # å°è¯•ä½¿ç”¨ squeue å‘½ä»¤ï¼ˆSlurm æ ‡å‡†å‘½ä»¤ï¼‰
        result = subprocess.run(
            ['squeue', '-u', subprocess.getoutput('whoami'), '-h', '-o', '%i %T %Z'],
            capture_output=True,
            text=True,
            timeout=5
        )
        
        if result.returncode == 0:
            # è§£æè¾“å‡º: JOBID STATE WORK_DIR
            for line in result.stdout.strip().split('\n'):
                if not line:
                    continue
                
                parts = line.split()
                if len(parts) >= 3:
                    state = parts[1]
                    work_dir = parts[2]
                    
                    # åªå…³æ³¨ RUNNING, PENDING, CONFIGURING çŠ¶æ€çš„ä½œä¸š
                    if state in ['RUNNING', 'PENDING', 'CONFIGURING', 'R', 'PD', 'CF']:
                        # ä» WorkDir ä¸­æå–ä½œä¸šåç§°
                        work_path = Path(work_dir)
                        if batch_dir.resolve() in work_path.resolve().parents:
                            job_name = work_path.name
                            running_jobs.add(job_name)
        else:
            # squeue å¤±è´¥ï¼Œå°è¯• yhq å‘½ä»¤
            result = subprocess.run(
                ['yhq'],
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if result.returncode == 0:
                # è§£æ yhq è¾“å‡º
                for line in result.stdout.strip().split('\n'):
                    if not line or 'JOBID' in line:
                        continue
                    
                    parts = line.split()
                    if len(parts) >= 3:
                        job_name = parts[2]  # NAME åˆ—
                        state = parts[4]     # ST åˆ—
                        
                        # R = RUNNING, PD = PENDING
                        if state in ['R', 'PD', 'CF']:
                            running_jobs.add(job_name)
    
    except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
        # å¦‚æœå‘½ä»¤å¤±è´¥ï¼Œè¿”å›ç©ºé›†åˆï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰
        pass
    
    return running_jobs


